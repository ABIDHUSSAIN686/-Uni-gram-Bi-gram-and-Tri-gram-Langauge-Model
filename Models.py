# -*- coding: utf-8 -*-
"""Part1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vQzIE3fScZ8BhRwZbpBhZJSHnY6hZSk9

#**Generating the Uni, Bi, Tri-gram**
"""

class GenerateModels:

  def readDataset(self):
  # Dataset for designing model
    file = "/Dataset.txt"
    dataset = open(file, "r")
    return dataset

  def generateCorpus( self,dataset ):
  # Spliting the Dataset into words
    corpus=[]
    for sentence in dataset:
      corpus+=sentence.split()
    return corpus

  def generateVocabulary( self,corpus ):
  #Finding the unique words in the corpus 
    vocabulary = []
    data=""
    for word in corpus:
        data +=word+" "
        if word not in vocabulary:
            vocabulary.append(word)
    return vocabulary

  def generateUnigramArray(self,corpus ):
  # Designing the Uni-gram Array
    Unigram_Array={}
    for items in corpus:
      Unigram_Array[items] = corpus.count(items)
    return Unigram_Array

  def generateUnigramModel( self,Unigram_Array, corpus ):
  # Designing the Uni-gram Model 
    Unigram_Model={}
    for items in Unigram_Array.keys():
      Unigram_Model[items]=Unigram_Array[items]/len(corpus)
    return Unigram_Model

  def generateBigramArray(self,Unigram_Array, vocabulary ,corpus):
  # Designing the Bi-gram Array and Model
    Bigram_Array=dict()
    Bigram_Model=dict()
    for index1 in range(len(vocabulary)):
      Bigram_Array[vocabulary[index1]] = dict()
      for index in range(len(vocabulary)):
        if index < len(vocabulary): 
          Bigram_Array[vocabulary[index1]][vocabulary[index]]=0
    for index1 in range(len(vocabulary)):
      Bigram_Array[vocabulary[index1]] = dict()
      Bigram_Model[vocabulary[index1]] = dict()
      for index in range(len(vocabulary)):
        if index < len(vocabulary):
          searched_word=vocabulary[index1]+" "+vocabulary[index]
          count =0
          for words in range(len(corpus)):
            if words < len(corpus)-1:
              if searched_word==corpus[words]+" "+corpus[words+1]:
                count+=1
          Bigram_Array[vocabulary[index1]][vocabulary[index]]=count
          Bigram_Model[vocabulary[index1]][vocabulary[index]]=(count+1)/(Unigram_Array[vocabulary[index1]]+len(vocabulary))
          
    return Bigram_Array,Bigram_Model


  def generateTrigramArray(self,Bigram_Array, vocabulary ,corpus):
  # Designing the Tri-gram Array and Model
    Trigram_Array=dict()
    Trigram_Model=dict()
    for index1 in range(len(corpus)):
      if index1 < len(corpus)-1:
        Trigram_Array[corpus[index1]+" "+corpus[index1+1]] = dict()
      for index in range(len(vocabulary)):
        if index1 < len(corpus)-1:
          sentence=corpus[index1]+" "+corpus[index1+1]
          Trigram_Array[sentence][vocabulary[index]]=0

    for index1 in range(len(corpus)):
      if index1 < len(corpus)-1:
        Trigram_Model[corpus[index1]+" "+corpus[index1+1]] = dict()
      for index in range(len(vocabulary)):
        if index1 < len(corpus)-1:
          searched_word=corpus[index1]+" "+corpus[index1+1]+" "+vocabulary[index]
          count =0
          for words in range(len(corpus)):
            if words < len(corpus)-2:
              if searched_word==corpus[words]+" "+corpus[words+1]+" "+corpus[words+2]:
                count+=1
          sentence=corpus[index1]+" "+corpus[index1+1]
          Trigram_Array[sentence][vocabulary[index]]=count
          Trigram_Model[sentence][vocabulary[index]]=(count+1)/(Bigram_Array[corpus[index1]][corpus[index1+1]]+len(vocabulary))
    
    return Trigram_Array,Trigram_Model




def main():
  model= GenerateModels()
  dataset =model.readDataset()
  corpus = model.generateCorpus(dataset)
  vocabulary = model.generateVocabulary(corpus)
  Unigram_Array = model.generateUnigramArray(corpus)
  Unigram_Model = model.generateUnigramModel(Unigram_Array,corpus)
  Bigram_Array,Bigram_Model = model.generateBigramArray(Unigram_Array, vocabulary ,corpus)
  Trigram_Array,Trigram_Model = model.generateTrigramArray(Bigram_Array, vocabulary ,corpus)
  # Printing all Models
  print('Unigram Array')
  print(Unigram_Array)
  print('Unigram Model')
  print(Unigram_Model)
  print('Bigram Array')
  print(Bigram_Array)
  print('Bigram Model')
  print(Bigram_Model)
  print('Trigram Array')
  print(Trigram_Array)
  print('Trigram Model')
  print(Trigram_Model)


if __name__ == "__main__":
    main()

"""# **Recursive N-Gram**"""

def readDataset():
# Dataset for designing model
  file = "/Dataset.txt"
  dataset = open(file, "r")
  return dataset

def generateCorpus(dataset ):
# Spliting the Dataset into words
  corpus=[]
  for sentence in dataset:
    corpus+=sentence.split()
  return corpus

def generateVocabulary( corpus ):
#Finding the unique words in the corpus 
  vocabulary = []
  data=""
  for word in corpus:
      data +=word+" "
      if word not in vocabulary:
          vocabulary.append(word)
  return vocabulary

def generateUnigramArray(corpus ):
#Designing the Uni-gram Array
  Unigram_Array={}
  for items in corpus:
    Unigram_Array[items] = corpus.count(items)
  return Unigram_Array


size=5
def recursivengram(n,ngram_Array,vocabulary,corpus):
  #Recursive Function for generating n-gram
  previousgram=ngram_Array
  ngram_Array={}
  ngram_Model={}
  for index1 in range(len(corpus)):
    sentence=""
    if index1 < len(corpus)-(n-1):
      for i in range(n-1):
        if(i==0 and index1 < len(corpus)-(n-1)):
          sentence+=corpus[index1]
        else:
          if index1 < len(corpus)-(n-1):
            sentence+=" "+corpus[index1+i]
      ngram_Array[sentence] = dict()
      ngram_Model[sentence] = dict()
      for index in range(len(vocabulary)):
        ngram_Array[sentence][vocabulary[index]]=0 

  searched_word=""
  searched_word1=""
  for index1 in range(len(corpus)):
    if index1 < len(corpus)-(n-1):
      sentence=""
      for i in range(n-1):
        if(i==0):
          sentence+=corpus[index1]
        else:
          if index1 < len(corpus)-(n-1):
            sentence+=" "+corpus[index1+i]
      
      for index in range(len(vocabulary)):
        searched_word=""
        for i in range(n-1):
          if(i==0):
            searched_word+=corpus[index1]
          elif i>0 and i<n: 
            if index1 < len(corpus)-(n-1):
              searched_word+=" "+corpus[index1+i]
        
        searched_word+=" "+ vocabulary[index] 
        count =0
        for words in range(len(corpus)):
          searched_word1=""
          for i in range(n):
            if i==0:
              searched_word1+=corpus[words+i]
            elif words < len(corpus)-(n-1):
              searched_word1+=" "+corpus[words+i]
          if searched_word==searched_word1:
            count+=1
          
          ngram_Array[sentence][vocabulary[index]]=count
          word1=""
          word2=""  
          temp=[]
          temp=sentence.split()      
          for i in range(len(temp)):
            if i==0:
              word1+=temp[i]
            if i>0 and i<len(temp)-1:
              word1+=" "+temp[i]
            if i==len(temp)-1:
              word2=temp[i]
          if (n>2):
            ngram_Model[sentence][vocabulary[index]]=(count+1)/(previousgram[word1][word2]+len(vocabulary))  
  if size==n:
    return ngram_Array,previousgram,ngram_Model

  return recursivengram(n+1,ngram_Array,vocabulary,corpus)



def main():
  dataset =readDataset()
  corpus = generateCorpus(dataset)
  vocabulary = generateVocabulary(corpus)
  Unigram_Array = generateUnigramArray(corpus)
  Bigram=dict()
  ngram_Array,previousgram,ngram_Model=recursivengram(2,Bigram,vocabulary,corpus)

  # Printing all Models
  print('Unigram Array')
  print(Unigram_Array)
  print('previousgram Array')
  print(previousgram)
  print('ngram Array')
  print(ngram_Array)
  print('ngram Model')
  print(ngram_Model)


if __name__ == "__main__":
    main()